{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Dueling Deep Q Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import gym, math, glob\n",
    "import numpy as np\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "from environments.BHS.environment_v4_2 import Environment\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import NNConv\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "from utils.wrappers import *\n",
    "from agents.DQN import Model as DQN_Agent\n",
    "from utils.ReplayMemory import ExperienceReplayMemory\n",
    "\n",
    "from utils.hyperparameters import Config\n",
    "from utils.plot import plot_all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#epsilon variables\n",
    "config.epsilon_start = 1.0\n",
    "config.epsilon_final = 0.01\n",
    "config.epsilon_decay = 300000\n",
    "config.epsilon_by_frame = lambda frame_idx: config.epsilon_final + (config.epsilon_start - config.epsilon_final) * math.exp(-1. * frame_idx / config.epsilon_decay)\n",
    "\n",
    "#misc agent variables\n",
    "config.GAMMA=0.99\n",
    "config.LR=1e-4\n",
    "config.USE_PRIORITY_REPLAY = True\n",
    "\n",
    "#memory\n",
    "config.TARGET_NET_UPDATE_FREQ = 1000\n",
    "config.EXP_REPLAY_SIZE = 50000\n",
    "config.BATCH_SIZE = 32\n",
    "\n",
    "#Learning control variables\n",
    "config.LEARN_START = 100\n",
    "config.MAX_FRAMES=1000000\n",
    "config.UPDATE_FREQ = 1\n",
    "\n",
    "#Nstep controls\n",
    "config.N_STEPS=5\n",
    "\n",
    "#data logging parameters\n",
    "config.ACTION_SELECTION_COUNT_FREQUENCY = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BHSDuelingDQN(nn.Module):\n",
    "    def __init__(self, input_shape, num_outputs, graph, edgelist, edge_attr, edge_nodes):\n",
    "        super(BHSDuelingDQN, self).__init__()\n",
    "        self.input_shape = list(input_shape)\n",
    "        self.input_shape[0] = graph.number_of_nodes()\n",
    "        self.num_actions = num_outputs # a vector of the number of actions at each diverter\n",
    "        self.edge = edgelist\n",
    "        self.edge_attr = edge_attr\n",
    "        self.edge_nodes = edge_nodes\n",
    "        \n",
    "        nn1 = nn.Sequential(nn.Linear(1, 64), nn.ReLU(), nn.Linear(64, self.input_shape[1]*128)) # edge attribute neural network\n",
    "        self.conv1 = NNConv(self.input_shape[1], 128, nn1)\n",
    "        \n",
    "        self.adv = nn.Linear(self.feature_size(), sum(self.num_actions)) # Might be an idea to add another fc layer here\n",
    "\n",
    "        self.val1 = nn.Linear(self.feature_size(), 64)\n",
    "        self.val2 = nn.Linear(64, 64)\n",
    "        self.val3 = nn.Linear(64, len(self.num_actions))\n",
    "\n",
    "    def forward(self, x):        \n",
    "        # x comes in as an N x H x C shape (N is batch size, H is number of elements (height), C is number of features (channels))\n",
    "        x_shape = x.shape\n",
    "        \n",
    "        start_down=timer()\n",
    "        x_down = torch.zeros([x_shape[0],self.input_shape[0],x_shape[2]])\n",
    "        edge_occu = [0]*len(self.edge_nodes)\n",
    "        for n in range(x_shape[0]):\n",
    "            i = 0\n",
    "            for k in range(x_shape[1]):\n",
    "                if (k in self.edge):\n",
    "                    x_down[n][i] = x[n][k]\n",
    "                    i += 1\n",
    "                else:\n",
    "                    for e in range(len(self.edge_nodes)):\n",
    "                        if k in self.edge_nodes[e]:\n",
    "                            if len(torch.nonzero(x[n][k],as_tuple=False)) != 0:\n",
    "                                edge_occu[e] += 1\n",
    "                            break\n",
    "\n",
    "        edge_attr = torch.Tensor(list(np.array(self.edge_attr) - np.array(edge_occu)))\n",
    "        x_shape = x_down.shape\n",
    "        x = x_down.view(x_shape[0]*x_shape[1],x_shape[2]) # set shape of x to [N*H, C] to get the shape of a Graph batch\n",
    "        time_down = timer()-start_down\n",
    "        print('TIME DOWN = ',time_down, x_shape[0])\n",
    "        \n",
    "        x = F.relu(self.conv1(x, self.edge, edge_attr))\n",
    "        \n",
    "        x = x.view(x_shape[0], -1) # set shape of x to [N,:] to keep the batch size\n",
    "        \n",
    "        adv = F.relu(self.adv(x))\n",
    "        adv = adv.view(adv.size(0),len(self.num_actions),-1)\n",
    "            \n",
    "        val = F.relu(self.val1(x))\n",
    "        val = F.relu(self.val2(val))\n",
    "        val = self.val3(val)\n",
    "        \n",
    "        return val.unsqueeze(-1).expand_as(adv) + adv - adv.mean(-1).unsqueeze(-1).expand_as(adv)\n",
    "    \n",
    "    def feature_size(self):\n",
    "        x = self.conv1(\n",
    "                    torch.zeros([self.input_shape[0],self.input_shape[1]],dtype=torch.float),\n",
    "                    torch.zeros([self.edge.shape[0],self.edge.shape[1]], dtype=torch.long),\n",
    "                    torch.zeros([self.edge.shape[1]],dtype=torch.float))\n",
    "        x = x.view(1, -1)\n",
    "        x = x.size(1)\n",
    "        return x\n",
    "    \n",
    "    def sample_noise(self):\n",
    "        #ignore this for now\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(DQN_Agent):\n",
    "    def __init__(self, static_policy=False, env=None, config=None, log_dir='/tmp/TEST'):\n",
    "        super(Model, self).__init__(static_policy, env, config, log_dir=log_dir)\n",
    "\n",
    "    def declare_networks(self):\n",
    "        graph = self.env.down_graph.to(self.device)\n",
    "        edgelist = self.env.edgelist_down.to(self.device)\n",
    "        edge_attr = self.env.edge_attr\n",
    "        edge_nodes = self.env.edge_nodes\n",
    "        self.model = BHSDuelingDQN(self.env.observation_space.shape, self.env.action_space.nvec, graph, edgelist, edge_attr, edge_nodes)\n",
    "        self.target_model = BHSDuelingDQN(self.env.observation_space.shape, self.env.action_space.nvec, graph, edgelist, edge_attr, edge_nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in environment:  101\n",
      "RL_DIVERTERS [2, 5, 13, 19, 26, 37, 92]\n",
      "TIME DOWN =  0.0032586999999999477 1\n",
      "TIME DOWN =  0.004304499999999933 1\n",
      "TIME DOWN =  0.002811300000000294 1\n",
      "TIME DOWN =  0.00255150000000004 1\n",
      "TIME DOWN =  0.002842799999999812 1\n",
      "TIME DOWN =  0.0025933000000000206 1\n",
      "TIME DOWN =  0.0024975999999998777 1\n",
      "TIME DOWN =  0.0025140999999999636 1\n",
      "TIME DOWN =  0.002526699999999771 1\n",
      "TIME DOWN =  0.00273719999999944 1\n",
      "TIME DOWN =  0.002815500000000526 1\n",
      "TIME DOWN =  0.002535200000000515 1\n",
      "TIME DOWN =  0.002511799999999731 1\n",
      "TIME DOWN =  0.0025574999999999903 1\n",
      "TIME DOWN =  0.0025642000000001275 1\n",
      "TIME DOWN =  0.0024714000000001235 1\n",
      "TIME DOWN =  0.002553999999999945 1\n",
      "TIME DOWN =  0.0024217999999995854 1\n",
      "TIME DOWN =  0.002437699999999765 1\n",
      "TIME DOWN =  0.002514199999999356 1\n",
      "TIME DOWN =  0.002399800000000063 1\n",
      "TIME DOWN =  0.003020099999999637 1\n",
      "TIME DOWN =  0.004242300000000476 1\n",
      "TIME DOWN =  0.002886299999999231 1\n",
      "TIME DOWN =  0.002937700000000376 1\n",
      "TIME DOWN =  0.002946500000000185 1\n",
      "TIME DOWN =  0.002976300000000265 1\n",
      "TIME DOWN =  0.003347800000000234 1\n",
      "TIME DOWN =  0.002719599999999822 1\n",
      "TIME DOWN =  0.004044700000000567 1\n",
      "TIME DOWN =  0.003757699999999531 1\n",
      "TIME DOWN =  0.004199700000000028 1\n",
      "TIME DOWN =  0.003914299999999926 1\n",
      "TIME DOWN =  0.003136099999999864 1\n",
      "TIME DOWN =  0.0029911999999994165 1\n",
      "TIME DOWN =  0.0032204999999994044 1\n",
      "TIME DOWN =  0.002500300000000344 1\n",
      "TIME DOWN =  0.0027770000000000294 1\n",
      "TIME DOWN =  0.0036227000000002008 1\n",
      "TIME DOWN =  0.002952599999999528 1\n",
      "TIME DOWN =  0.0027452999999999506 1\n",
      "TIME DOWN =  0.003229399999999494 1\n",
      "TIME DOWN =  0.002850999999999715 1\n",
      "TIME DOWN =  0.0028930000000002565 1\n",
      "TIME DOWN =  0.003212699999999735 1\n",
      "TIME DOWN =  0.002996399999999788 1\n",
      "TIME DOWN =  0.0026805999999997 1\n",
      "TIME DOWN =  0.0030216000000002907 1\n",
      "TIME DOWN =  0.0026576000000000377 1\n",
      "TIME DOWN =  0.004271699999999434 1\n",
      "TIME DOWN =  0.004288900000000595 1\n",
      "TIME DOWN =  0.0024575000000002234 1\n",
      "TIME DOWN =  0.002492099999999553 1\n",
      "TIME DOWN =  0.0028074000000000154 1\n",
      "TIME DOWN =  0.002518400000000476 1\n",
      "TIME DOWN =  0.0025545999999998514 1\n",
      "TIME DOWN =  0.0025002000000000635 1\n",
      "TIME DOWN =  0.0025372999999992984 1\n",
      "TIME DOWN =  0.0026679999999998927 1\n",
      "TIME DOWN =  0.002555300000000038 1\n",
      "TIME DOWN =  0.003270999999999802 1\n",
      "TIME DOWN =  0.0026636999999993805 1\n",
      "TIME DOWN =  0.0045690999999994375 1\n",
      "TIME DOWN =  0.0033957000000004456 1\n",
      "TIME DOWN =  0.0027455999999999037 1\n",
      "TIME DOWN =  0.002645199999999903 1\n",
      "TIME DOWN =  0.0026869000000004917 1\n",
      "TIME DOWN =  0.002649199999999574 1\n",
      "TIME DOWN =  0.002733700000000283 1\n",
      "TIME DOWN =  0.002587800000000584 1\n",
      "TIME DOWN =  0.002787599999999557 1\n",
      "TIME DOWN =  0.002639499999999906 1\n",
      "TIME DOWN =  0.0025762000000000285 1\n",
      "TIME DOWN =  0.0038201999999998293 1\n",
      "TIME DOWN =  0.003095799999999649 1\n",
      "TIME DOWN =  0.002467800000000686 1\n",
      "TIME DOWN =  0.0024618999999992397 1\n",
      "TIME DOWN =  0.002693199999999507 1\n",
      "TIME DOWN =  0.0024750999999998413 1\n",
      "TIME DOWN =  0.002468300000000312 1\n",
      "TIME DOWN =  0.002485700000000257 1\n",
      "TIME DOWN =  0.0025007000000005775 1\n",
      "TIME DOWN =  0.0024568000000000367 1\n",
      "TIME DOWN =  0.0024746000000002155 1\n",
      "TIME DOWN =  0.004041600000000756 1\n",
      "TIME DOWN =  0.003281399999999657 1\n",
      "TIME DOWN =  0.002992899999999743 1\n",
      "TIME DOWN =  0.00297769999999975 1\n",
      "TIME DOWN =  0.0029512000000000427 1\n",
      "TIME DOWN =  0.0029826999999995607 1\n",
      "TIME DOWN =  0.002965399999999896 1\n",
      "TIME DOWN =  0.002948400000000184 1\n",
      "TIME DOWN =  0.0029548999999997605 1\n",
      "TIME DOWN =  0.0030600000000005068 1\n",
      "TIME DOWN =  0.004251599999999911 1\n",
      "TIME DOWN =  0.002490500000000395 1\n",
      "TIME DOWN =  0.004276200000000507 1\n",
      "TIME DOWN =  0.005516499999999702 1\n",
      "TIME DOWN =  0.002599599999999924 1\n",
      "TIME DOWN =  0.004555000000000753 1\n",
      "TIME DOWN =  0.1289701000000001 32\n",
      "TIME DOWN =  0.09737330000000011 32\n",
      "TIME DOWN =  0.08600329999999978 32\n",
      "TIME DOWN =  0.006712100000000554 1\n",
      "TIME DOWN =  0.16696139999999993 32\n",
      "TIME DOWN =  0.09657729999999987 32\n",
      "TIME DOWN =  0.08762100000000039 32\n",
      "TIME DOWN =  0.00401720000000072 1\n",
      "TIME DOWN =  0.1641433999999995 32\n",
      "TIME DOWN =  0.12017300000000031 32\n",
      "TIME DOWN =  0.12357339999999972 32\n",
      "TIME DOWN =  0.006902000000000186 1\n",
      "TIME DOWN =  0.19647229999999993 32\n",
      "TIME DOWN =  0.11859899999999968 32\n",
      "TIME DOWN =  0.0976271999999998 32\n",
      "TIME DOWN =  0.003089699999999418 1\n",
      "TIME DOWN =  0.1745051000000002 32\n",
      "TIME DOWN =  0.12941760000000002 32\n",
      "TIME DOWN =  0.1334401000000005 32\n",
      "TIME DOWN =  0.006955699999999787 1\n",
      "TIME DOWN =  0.15169939999999915 32\n",
      "TIME DOWN =  0.16406800000000032 32\n",
      "TIME DOWN =  0.14503759999999843 32\n",
      "TIME DOWN =  0.006856099999998477 1\n",
      "TIME DOWN =  0.17649019999999993 32\n",
      "TIME DOWN =  0.1370880999999997 32\n",
      "TIME DOWN =  0.11261550000000042 32\n",
      "TIME DOWN =  0.006956799999999319 1\n",
      "TIME DOWN =  0.16479920000000092 32\n",
      "TIME DOWN =  0.12357939999999878 32\n",
      "TIME DOWN =  0.12176229999999855 32\n",
      "TIME DOWN =  0.005159099999998418 1\n",
      "TIME DOWN =  0.16330169999999988 32\n",
      "TIME DOWN =  0.10885660000000108 32\n",
      "TIME DOWN =  0.0932542999999999 32\n",
      "TIME DOWN =  0.004146699999999726 1\n",
      "TIME DOWN =  0.1655002999999997 32\n",
      "TIME DOWN =  0.10367029999999922 32\n",
      "TIME DOWN =  0.1179977000000001 32\n",
      "TIME DOWN =  0.00306940000000111 1\n",
      "TIME DOWN =  0.15781550000000166 32\n",
      "TIME DOWN =  0.13196559999999913 32\n",
      "TIME DOWN =  0.11298390000000147 32\n",
      "TIME DOWN =  0.007038800000000123 1\n",
      "TIME DOWN =  0.15351279999999967 32\n",
      "TIME DOWN =  0.1293861000000014 32\n",
      "TIME DOWN =  0.13572789999999912 32\n",
      "TIME DOWN =  0.004152700000000564 1\n",
      "TIME DOWN =  0.17209369999999957 32\n",
      "TIME DOWN =  0.11664410000000025 32\n",
      "TIME DOWN =  0.12695040000000013 32\n",
      "TIME DOWN =  0.005558300000000571 1\n",
      "TIME DOWN =  0.14571360000000055 32\n",
      "TIME DOWN =  0.1261858999999994 32\n",
      "TIME DOWN =  0.11242090000000005 32\n",
      "TIME DOWN =  0.005393100000000928 1\n",
      "TIME DOWN =  0.1766868000000006 32\n",
      "TIME DOWN =  0.14816170000000106 32\n",
      "TIME DOWN =  0.13601459999999932 32\n",
      "TIME DOWN =  0.006910400000000649 1\n",
      "TIME DOWN =  0.18752480000000027 32\n",
      "TIME DOWN =  0.15125390000000039 32\n",
      "TIME DOWN =  0.16930379999999978 32\n",
      "TIME DOWN =  0.004895900000001063 1\n",
      "TIME DOWN =  0.18828459999999936 32\n",
      "TIME DOWN =  0.1443019999999997 32\n",
      "TIME DOWN =  0.14216980000000135 32\n",
      "TIME DOWN =  0.0035959999999999326 1\n",
      "TIME DOWN =  0.13082680000000124 32\n",
      "TIME DOWN =  0.12685429999999975 32\n",
      "TIME DOWN =  0.09732630000000064 32\n",
      "TIME DOWN =  0.00605089999999997 1\n",
      "TIME DOWN =  0.16827329999999918 32\n",
      "TIME DOWN =  0.08896329999999963 32\n",
      "TIME DOWN =  0.0991452000000006 32\n",
      "TIME DOWN =  0.006830600000000686 1\n",
      "TIME DOWN =  0.12690040000000025 32\n",
      "TIME DOWN =  0.13524349999999963 32\n",
      "TIME DOWN =  0.10513000000000083 32\n",
      "TIME DOWN =  0.005060600000000193 1\n",
      "TIME DOWN =  0.1402215000000009 32\n",
      "TIME DOWN =  0.12130389999999913 32\n",
      "TIME DOWN =  0.11851760000000056 32\n",
      "TIME DOWN =  0.0030279999999986984 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d82d17ac0b4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mstart_update\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_observation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[0mepisode_reward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mtime_update\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart_update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Github\\DeepRL-Tutorials\\agents\\DQN.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, s, a, r, s_, frame)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mbatch_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprep_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;31m# Optimize the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Github\\DeepRL-Tutorials\\agents\\DQN.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[1;34m(self, batch_vars, s_)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;31m#estimate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_noise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mcurrent_q_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[1;31m#target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\BHS_Pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-16af181a9c63>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                     \u001b[0mx_down\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\BHS_Pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36m__contains__\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m    510\u001b[0m         \"\"\"\n\u001b[0;32m    511\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         raise RuntimeError(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\BHS_Pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start=timer()\n",
    "\n",
    "log_dir = \"tmp/TEST/\"\n",
    "try:\n",
    "    os.makedirs(log_dir)\n",
    "except OSError:\n",
    "    files = glob.glob(os.path.join(log_dir, '*.monitor.csv')) \\\n",
    "        + glob.glob(os.path.join(log_dir, '*td.csv')) \\\n",
    "        + glob.glob(os.path.join(log_dir, '*sig_param_mag.csv')) \\\n",
    "        + glob.glob(os.path.join(log_dir, '*action_log.csv'))\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "\n",
    "class Arg_parser():\n",
    "    def __init__(self):\n",
    "        self.max_timesteps = 10000000\n",
    "        self.envtype = 'env_2_0'\n",
    "        self.tb_log_name = 'DQN'\n",
    "        self.steplimit = 200\n",
    "        self.log_interval = 1000\n",
    "        self.step_penalty = None\n",
    "        self.trasum_scale = None\n",
    "        self.destination_score = None\n",
    "        self.numtotes = 30\n",
    "        self.randomize_numtotes = False\n",
    "        self.RL_diverters = None\n",
    "    \n",
    "args = Arg_parser()\n",
    "\n",
    "        \n",
    "env_id = args.envtype\n",
    "env    = Environment(args) #make_atari(env_id)\n",
    "env    = bench.Monitor(env, os.path.join(log_dir, env_id))\n",
    "# env    = wrap_deepmind(env, episode_life=True, clip_rewards=True, frame_stack=False, scale=True)\n",
    "# env    = ImageToPyTorch(env)\n",
    "model  = Model(env=env, config=config, log_dir=log_dir)\n",
    "\n",
    "episode_reward = 0\n",
    "time_get, time_step, time_update = 0,0,0\n",
    "observation = env.reset(total = True)\n",
    "for frame_idx in range(1, config.MAX_FRAMES + 1):\n",
    "    epsilon = config.epsilon_by_frame(frame_idx)\n",
    "    \n",
    "    start_get=timer()\n",
    "    action = model.get_action(observation, epsilon)[0]\n",
    "    time_get += timer()-start_get\n",
    "    \n",
    "    start_step=timer()\n",
    "    prev_observation=observation\n",
    "    observation, reward, done, _, actual_action = env.step(action)\n",
    "    observation = None if env.deadlock else observation     \n",
    "    time_step += timer()-start_step\n",
    "    \n",
    "    action = actual_action\n",
    "    model.save_action(action, frame_idx) #log action selection\n",
    "    \n",
    "    start_update=timer()\n",
    "    model.update(prev_observation, action, reward, observation, frame_idx)\n",
    "    episode_reward += reward\n",
    "    time_update += timer()-start_update   \n",
    "    \n",
    "    if frame_idx % args.steplimit*10 == 0:\n",
    "        total_reset = True\n",
    "    else:\n",
    "        total_reset = env.deadlock\n",
    "    if done:\n",
    "        model.finish_nstep()\n",
    "        model.reset_hx()\n",
    "        \n",
    "        observation = env.reset(total=total_reset)\n",
    "        model.save_reward(episode_reward)\n",
    "        episode_reward = 0\n",
    "    \n",
    "    \n",
    "    if frame_idx % args.log_interval == 0:\n",
    "        model.save_w()\n",
    "        try:\n",
    "            clear_output(True)\n",
    "            print(frame_idx)\n",
    "            print(time_get/args.log_interval, time_step/args.log_interval, time_update/args.log_interval)\n",
    "            time_get, time_step, time_update = 0,0,0\n",
    "            plot_all_data(log_dir, env_id, 'BHSDuelingDQN', config.MAX_FRAMES, bin_size=(10, 100, 100, 1), smooth=1, time=timedelta(seconds=int(timer()-start)), ipynb=True)\n",
    "        except IOError:\n",
    "            pass\n",
    "\n",
    "model.save_w()\n",
    "env.close()\n",
    "plot_all_data(log_dir, env_id, 'BHSDuelingDQN', config.MAX_FRAMES, bin_size=(10, 100, 100, 1), smooth=1, time=timedelta(seconds=int(timer()-start)), ipynb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
