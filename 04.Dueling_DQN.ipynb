{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Dueling Deep Q Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import gym, math, glob, sys\n",
    "import numpy as np\n",
    "import datetime\n",
    "import csv\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "from environments.BHS.environment_v5_0 import Environment\n",
    "from networks.Models import BHSDuelingDQN, BHS_GCN, BHS_SGN, BHS_GIN, BHS_SAGE, BHS_GAT, BHS_GGNN, BHS_NN, BHS_CG, BHS_PNA, BHS_TEST, BHS_GCN_DQN\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "from utils.wrappers import *\n",
    "from agents.DQN import Model as DQN_Agent\n",
    "from utils.ReplayMemory import ExperienceReplayMemory\n",
    "\n",
    "from utils.hyperparameters import Config\n",
    "from utils.plot import plot_all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#epsilon variables\n",
    "config.epsilon_start = 0.5\n",
    "config.epsilon_final = 0.02\n",
    "config.epsilon_decay = 1000000\n",
    "config.epsilon_by_frame = lambda frame_idx: config.epsilon_final + (config.epsilon_start - config.epsilon_final) * math.exp(-1. * frame_idx / config.epsilon_decay)\n",
    "\n",
    "#misc agent variables\n",
    "config.GAMMA=0.99\n",
    "config.LR=1e-3\n",
    "config.USE_PRIORITY_REPLAY = True\n",
    "\n",
    "#memory\n",
    "config.TARGET_NET_UPDATE_FREQ = 1000\n",
    "config.EXP_REPLAY_SIZE = 100000\n",
    "config.BATCH_SIZE = 32\n",
    "\n",
    "#Learning control variables\n",
    "config.LEARN_START = 100\n",
    "config.MAX_FRAMES=1000000\n",
    "config.UPDATE_FREQ = 1\n",
    "\n",
    "#Nstep controls\n",
    "config.N_STEPS=1\n",
    "\n",
    "#data logging parameters\n",
    "config.ACTION_SELECTION_COUNT_FREQUENCY = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Agent & Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(DQN_Agent):\n",
    "    def __init__(self, static_policy=False, env=None, config=None, log_dir='tmp/gym/', network =\"DQN\", downsampled = False):\n",
    "        super(Model, self).__init__(static_policy, env, config, log_dir=log_dir)\n",
    "        \n",
    "\n",
    "    def declare_networks(self):\n",
    "        if (network == \"DQN\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                self.model = BHSDuelingDQN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec)\n",
    "                self.target_model = BHSDuelingDQN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec)\n",
    "            else: \n",
    "                self.model = BHSDuelingDQN(self.env.observation_space.shape, self.env.action_space.nvec)\n",
    "                self.target_model = BHSDuelingDQN(self.env.observation_space.shape, self.env.action_space.nvec)\n",
    "            \n",
    "        elif (network == \"GCN\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                edge_weight = self.env.edge_attr.to(self.device)\n",
    "                self.model = BHS_GCN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                self.target_model = BHS_GCN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_weight)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                edge_weight = torch.ones([edgelist.shape[1]],dtype=torch.float).to(self.device)\n",
    "                self.model = BHS_GCN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                self.target_model = BHS_GCN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                \n",
    "        elif (network == \"GAT\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                self.model = BHS_GAT([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist)\n",
    "                self.target_model = BHS_GAT([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                self.model = BHS_GAT(self.env.observation_space.shape, self.env.action_space.nvec, edgelist)\n",
    "                self.target_model = BHS_GAT(self.env.observation_space.shape, self.env.action_space.nvec, edgelist)\n",
    "                \n",
    "        elif (network == \"SGN\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                edge_weight = self.env.edge_attr.to(self.device)\n",
    "                self.model = BHS_SGN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                self.target_model = BHS_SGN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_weight)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                edge_weight = torch.ones([edgelist.shape[1]],dtype=torch.float).to(self.device)\n",
    "                self.model = BHS_SGN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                self.target_model = BHS_SGN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                \n",
    "        elif (network == \"GGNN\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                edge_weight = self.env.edge_attr.to(self.device)\n",
    "                self.model = BHS_GGNN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                self.target_model = BHS_GGNN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_weight)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                edge_weight = torch.ones([edgelist.shape[1]],dtype=torch.float).to(self.device)\n",
    "                self.model = BHS_GGNN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                self.target_model = BHS_GGNN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_weight)\n",
    "            \n",
    "        elif (network == \"SAGE\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                graph = self.env.graph_down.to(self.device)\n",
    "                self.model = BHS_SAGE([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, graph)\n",
    "                self.target_model = BHS_SAGE([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, graph)\n",
    "            else: \n",
    "                graph = self.env.graph.to(self.device)\n",
    "                self.model = BHS_SAGE(self.env.observation_space.shape, self.env.action_space.nvec, graph)\n",
    "                self.target_model = BHS_SAGE(self.env.observation_space.shape, self.env.action_space.nvec, graph)\n",
    "            \n",
    "        elif (network == \"GIN\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                self.model = BHS_GIN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist)\n",
    "                self.target_model = BHS_GIN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                self.model = BHS_GIN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist)\n",
    "                self.target_model = BHS_GIN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist)\n",
    "            \n",
    "        elif (network == \"NN\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                edge_attr = self.env.edge_attr.to(self.device)\n",
    "                edge_attr = edge_attr.view(edge_attr.shape[0],1)\n",
    "                self.model = BHS_NN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_attr)\n",
    "                self.target_model = BHS_NN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_attr)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                edge_attr = torch.ones([edgelist.shape[1],1],dtype=torch.float).to(self.device)\n",
    "                self.model = BHS_NN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_attr)\n",
    "                self.target_model = BHS_NN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_attr)\n",
    "                \n",
    "        elif (network == \"CG\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                edge_attr = self.env.edge_attr.to(self.device)\n",
    "                edge_attr = edge_attr.view(edge_attr.shape[0],1)\n",
    "                self.model = BHS_CG([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_attr)\n",
    "                self.target_model = BHS_CG([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_attr)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                edge_attr = torch.ones([edgelist.shape[1],1],dtype=torch.float).to(self.device)\n",
    "                self.model = BHS_CG(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_attr)\n",
    "                self.target_model = BHS_CG(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_attr)\n",
    "                \n",
    "        elif (network == \"PNA\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                edge_attr = self.env.edge_attr.to(self.device)\n",
    "                edge_attr = edge_attr.view(edge_attr.shape[0],1)\n",
    "                self.model = BHS_PNA([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_attr)\n",
    "                self.target_model = BHS_PNA([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_attr)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                edge_attr = torch.ones([edgelist.shape[1],1],dtype=torch.float).to(self.device)\n",
    "                self.model = BHS_PNA(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_attr)\n",
    "                self.target_model = BHS_PNA(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_attr)\n",
    "            \n",
    "        elif (network == \"GCN_DQN\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                edge_weight = self.env.edge_attr.to(self.device)\n",
    "                self.model = BHS_GCN_DQN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                self.target_model = BHS_GCN_DQN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_weight)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                edge_weight = torch.ones([edgelist.shape[1]],dtype=torch.float).to(self.device)\n",
    "                self.model = BHS_GCN_DQN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                self.target_model = BHS_GCN_DQN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                \n",
    "        elif (network == \"TEST\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                edge_attr = self.env.edge_attr.to(self.device)\n",
    "                edge_attr = edge_attr.view(edge_attr.shape[0],1)\n",
    "                hidden = torch.zeros([1,len(self.env.nodes),128],dtype=torch.float).to(self.device)\n",
    "                self.model = BHS_TEST([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_attr, hidden)\n",
    "                self.target_model = BHS_TEST([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_attr, hidden)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                edge_attr = torch.ones([edgelist.shape[1],1],dtype=torch.float).to(self.device)\n",
    "                hidden = torch.zeros([5,self.env.observation_space.shape[0],128],dtype=torch.float).to(self.device)\n",
    "                self.model = BHS_TEST(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_attr, hidden)\n",
    "                self.target_model = BHS_TEST(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_attr, hidden)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Network not chosen - Choose DQN, GCN, GAT, SGN, GGNN, SAGE, GIN, NN, CG, PNA, GCN_DQN or TEST\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-04-01\n",
      "Number of elements in environment:  101\n",
      "Downsampled:  False\n",
      "Number of nodes in graph: 101\n",
      "Randomize number of totes:  False\n",
      "Number of totes: 30\n",
      "RL_DIVERTERS [2, 5, 13, 19, 26, 37, 92]\n",
      "Model = NN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\frede\\Anaconda3\\envs\\BHS_Pytorch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-b734f767dcc8>\", line 92, in <module>\n",
      "    model.update(prev_observation, action, reward, observation, frame_idx)\n",
      "  File \"C:\\Users\\frede\\Desktop\\Github\\DeepRL-Tutorials\\agents\\DQN.py\", line 139, in update\n",
      "    loss = self.compute_loss(batch_vars, s_)\n",
      "  File \"C:\\Users\\frede\\Desktop\\Github\\DeepRL-Tutorials\\agents\\DQN.py\", line 114, in compute_loss\n",
      "    max_next_q_values[non_final_mask] = self.target_model(non_final_next_states).gather(-1, max_next_action)\n",
      "  File \"C:\\Users\\frede\\Anaconda3\\envs\\BHS_Pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"C:\\Users\\frede\\Desktop\\Github\\DeepRL-Tutorials\\networks\\Models.py\", line 382, in forward\n",
      "    x = F.relu(self.conv1(x, self.edge, self.edge_attr))\n",
      "  File \"C:\\Users\\frede\\Anaconda3\\envs\\BHS_Pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 550, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"C:\\Users\\frede\\Anaconda3\\envs\\BHS_Pytorch\\lib\\site-packages\\torch_geometric\\nn\\conv\\nn_conv.py\", line 96, in forward\n",
      "    out += self.bias\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\frede\\Anaconda3\\envs\\BHS_Pytorch\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\frede\\Anaconda3\\envs\\BHS_Pytorch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\frede\\Anaconda3\\envs\\BHS_Pytorch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\frede\\Anaconda3\\envs\\BHS_Pytorch\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\frede\\Anaconda3\\envs\\BHS_Pytorch\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\frede\\Anaconda3\\envs\\BHS_Pytorch\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\frede\\Anaconda3\\envs\\BHS_Pytorch\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\frede\\Anaconda3\\envs\\BHS_Pytorch\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\frede\\Anaconda3\\envs\\BHS_Pytorch\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\frede\\Anaconda3\\envs\\BHS_Pytorch\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\frede\\Anaconda3\\envs\\BHS_Pytorch\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "start=timer()\n",
    "\n",
    "if (get_ipython().__class__.__name__ == \"ZMQInteractiveShell\"):\n",
    "    network = \"NN\"\n",
    "    downsampled = False\n",
    "    numtotes = 30\n",
    "    randomize_numtotes = False\n",
    "elif (len(sys.argv) > 3):\n",
    "    network = sys.argv[1]\n",
    "    downsampled = sys.argv[2]\n",
    "    totes = sys.argv[3]\n",
    "    if (downsampled == \"True\"):\n",
    "        downsampled = True\n",
    "    elif (downsampled == \"False\"):\n",
    "        downsampled = False\n",
    "    else:\n",
    "        raise ValueError(\"Downsampling not chosen - Choose True or False\")\n",
    "    if (totes == \"True\"):\n",
    "        randomize_numtotes = True\n",
    "        numtotes = 50\n",
    "    elif (totes.isnumeric()):\n",
    "        randomize_numtotes = False\n",
    "        numtotes = int(totes)\n",
    "    else:\n",
    "        raise ValueError(\"Number of totes not chosen - Choose a number or True or False\")\n",
    "else:\n",
    "    raise ValueError(\"Network or downsampling not chosen\")\n",
    "\n",
    "\n",
    "time = '{date:%Y-%m-%d-%H}'.format(date=datetime.datetime.now())\n",
    "print(time)\n",
    "\n",
    "log_dir = \"tmp/\" + network + \"/\" + network + \"_\" + time + \"/\"\n",
    "res_dir = \"Results/\" + network + \"/\"\n",
    "filename = res_dir + network + \"_\" + time\n",
    "try:\n",
    "    os.makedirs(res_dir, exist_ok = True)\n",
    "    os.makedirs(log_dir, exist_ok = True)\n",
    "except OSError:\n",
    "    files = glob.glob(os.path.join(log_dir, '*.monitor.csv')) \\\n",
    "        + glob.glob(os.path.join(log_dir, '*td.csv')) \\\n",
    "        + glob.glob(os.path.join(log_dir, '*sig_param_mag.csv')) \\\n",
    "        + glob.glob(os.path.join(log_dir, '*action_log.csv'))\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "\n",
    "class Arg_parser():\n",
    "    def __init__(self):\n",
    "        self.max_timesteps = 10000000\n",
    "        self.envtype = 'env_2_0'\n",
    "        self.tb_log_name = 'DQN'\n",
    "        self.steplimit = 200\n",
    "        self.log_interval = 1000\n",
    "        self.step_penalty = None\n",
    "        self.trasum_scale = None\n",
    "        self.destination_score = None\n",
    "        self.numtotes = numtotes\n",
    "        self.randomize_numtotes = randomize_numtotes\n",
    "        self.RL_diverters = None\n",
    "        self.downsampled = downsampled\n",
    "    \n",
    "args = Arg_parser()\n",
    "\n",
    "env_id = args.envtype\n",
    "env    = Environment(args) #make_atari(env_id)\n",
    "env    = bench.Monitor(env, os.path.join(log_dir, env_id))\n",
    "# env    = wrap_deepmind(env, episode_life=True, clip_rewards=True, frame_stack=False, scale=True)\n",
    "# env    = ImageToPyTorch(env)\n",
    "model  = Model(env=env, config=config, log_dir=log_dir, network=network, downsampled=downsampled)\n",
    "\n",
    "episode_reward = 0\n",
    "time_get, time_step, time_update = 0,0,0\n",
    "observation = env.reset(total = True)\n",
    "\n",
    "for frame_idx in range(1, config.MAX_FRAMES + 1):\n",
    "    epsilon = config.epsilon_by_frame(frame_idx)\n",
    "\n",
    "    start_get=timer()\n",
    "    action = model.get_action(observation, epsilon)[0]\n",
    "    time_get += timer()-start_get\n",
    "    \n",
    "    start_step=timer()\n",
    "    prev_observation=observation\n",
    "    observation, reward, done, _, actual_action = env.step(action)\n",
    "    observation = None if env.deadlock else observation\n",
    "    time_step += timer()-start_step\n",
    "    \n",
    "    action = actual_action\n",
    "    model.save_action(action, frame_idx) #log action selection\n",
    "    \n",
    "    start_update=timer()\n",
    "    model.update(prev_observation, action, reward, observation, frame_idx)\n",
    "    episode_reward += reward\n",
    "    time_update += timer()-start_update\n",
    "    \n",
    "    if frame_idx % args.steplimit*10 == 0:\n",
    "        total_reset = True\n",
    "    else:\n",
    "        total_reset = env.deadlock\n",
    "    if done:\n",
    "        model.finish_nstep()\n",
    "        model.reset_hx()\n",
    "        \n",
    "        observation = env.reset(total=total_reset)\n",
    "        model.save_reward(episode_reward)\n",
    "        episode_reward = 0\n",
    "    \n",
    "    \n",
    "    if frame_idx % args.log_interval == 0:\n",
    "        torch.save(model.get_state_dict(), filename + \".pt\") #model.save_w()\n",
    "        try:\n",
    "            clear_output(True)\n",
    "            print(frame_idx)\n",
    "            print(time_get/args.log_interval, time_step/args.log_interval, time_update/args.log_interval)\n",
    "            with open(filename+'.csv', mode='a',newline='') as time_file:\n",
    "                time_writer = csv.writer(time_file, delimiter=',')\n",
    "                time_writer.writerow([time_get/args.log_interval, time_step/args.log_interval, time_update/args.log_interval])\n",
    "                \n",
    "            time_get, time_step, time_update = 0,0,0\n",
    "            plot_all_data(log_dir, env_id, 'BHSDuelingDQN', config.MAX_FRAMES, bin_size=(10, 100, 100, 1), smooth=1, time=timedelta(seconds=int(timer()-start)), save_filename=filename+\".svg\", ipynb=False)\n",
    "        except IOError:\n",
    "            pass\n",
    "\n",
    "torch.save(model.get_state_dict(), filename + \".pt\") #model.save_w()\n",
    "env.close()\n",
    "plot_all_data(log_dir, env_id, 'BHSDuelingDQN', config.MAX_FRAMES, bin_size=(10, 100, 100, 1), smooth=1, time=timedelta(seconds=int(timer()-start)), save_filename=filename+\".svg\", ipynb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
