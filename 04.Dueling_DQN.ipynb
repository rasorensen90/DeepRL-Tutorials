{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Dueling Deep Q Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import gym, math, glob, sys\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "from environments.BHS.environment_v5_0 import Environment\n",
    "from networks.Models import BHSDuelingDQN, BHS_GCN, BHS_SGN, BHS_GIN, BHS_SAGE, BHS_GAT, BHS_GGNN, BHS_NN, BHS_CG, BHS_PNA, BHS_TEST, BHS_GCN_DQN\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "from utils.wrappers import *\n",
    "from agents.DQN import Model as DQN_Agent\n",
    "from utils.ReplayMemory import ExperienceReplayMemory\n",
    "\n",
    "from utils.hyperparameters import Config\n",
    "from utils.plot import plot_all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#epsilon variables\n",
    "config.epsilon_start = 1.0\n",
    "config.epsilon_final = 0.01\n",
    "config.epsilon_decay = 300000\n",
    "config.epsilon_by_frame = lambda frame_idx: config.epsilon_final + (config.epsilon_start - config.epsilon_final) * math.exp(-1. * frame_idx / config.epsilon_decay)\n",
    "\n",
    "#misc agent variables\n",
    "config.GAMMA=0.99\n",
    "config.LR=1e-4\n",
    "config.USE_PRIORITY_REPLAY = True\n",
    "\n",
    "#memory\n",
    "config.TARGET_NET_UPDATE_FREQ = 1000\n",
    "config.EXP_REPLAY_SIZE = 50000\n",
    "config.BATCH_SIZE = 32\n",
    "\n",
    "#Learning control variables\n",
    "config.LEARN_START = 100\n",
    "config.MAX_FRAMES=1000000\n",
    "config.UPDATE_FREQ = 1\n",
    "\n",
    "#Nstep controls\n",
    "config.N_STEPS=5\n",
    "\n",
    "#data logging parameters\n",
    "config.ACTION_SELECTION_COUNT_FREQUENCY = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Agent & Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(DQN_Agent):\n",
    "    def __init__(self, static_policy=False, env=None, config=None, log_dir='tmp/gym/', network =\"DQN\", downsampled = False):\n",
    "        super(Model, self).__init__(static_policy, env, config, log_dir=log_dir)\n",
    "\n",
    "    def declare_networks(self):\n",
    "        if (network == \"DQN\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                self.model = BHSDuelingDQN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec)\n",
    "                self.target_model = BHSDuelingDQN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec)\n",
    "            else: \n",
    "                self.model = BHSDuelingDQN(self.env.observation_space.shape, self.env.action_space.nvec)\n",
    "                self.target_model = BHSDuelingDQN(self.env.observation_space.shape, self.env.action_space.nvec)\n",
    "            \n",
    "        elif (network == \"GCN\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                edge_weight = self.env.edge_attr.to(self.device)\n",
    "                self.model = BHS_GCN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                self.target_model = BHS_GCN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_weight)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                edge_weight = torch.ones([edgelist.shape[1]],dtype=torch.float).to(self.device)\n",
    "                self.model = BHS_GCN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                self.target_model = BHS_GCN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                \n",
    "        elif (network == \"GAT\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                self.model = BHS_GAT([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist)\n",
    "                self.target_model = BHS_GAT([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                self.model = BHS_GAT(self.env.observation_space.shape, self.env.action_space.nvec, edgelist)\n",
    "                self.target_model = BHS_GAT(self.env.observation_space.shape, self.env.action_space.nvec, edgelist)\n",
    "                \n",
    "        elif (network == \"SGN\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                edge_weight = self.env.edge_attr.to(self.device)\n",
    "                self.model = BHS_SGN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                self.target_model = BHS_SGN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_weight)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                edge_weight = torch.ones([edgelist.shape[1]],dtype=torch.float).to(self.device)\n",
    "                self.model = BHS_SGN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                self.target_model = BHS_SGN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                \n",
    "        elif (network == \"GGNN\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                edge_weight = self.env.edge_attr.to(self.device)\n",
    "                self.model = BHS_GGNN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                self.target_model = BHS_GGNN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_weight)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                edge_weight = torch.ones([edgelist.shape[1]],dtype=torch.float).to(self.device)\n",
    "                self.model = BHS_GGNN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                self.target_model = BHS_GGNN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_weight)\n",
    "            \n",
    "        elif (network == \"SAGE\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                graph = self.env.graph_down.to(self.device)\n",
    "                self.model = BHS_SAGE([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, graph)\n",
    "                self.target_model = BHS_SAGE([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, graph)\n",
    "            else: \n",
    "                graph = self.env.graph.to(self.device)\n",
    "                self.model = BHS_SAGE(self.env.observation_space.shape, self.env.action_space.nvec, graph)\n",
    "                self.target_model = BHS_SAGE(self.env.observation_space.shape, self.env.action_space.nvec, graph)\n",
    "            \n",
    "        elif (network == \"GIN\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                self.model = BHS_GIN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist)\n",
    "                self.target_model = BHS_GIN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                self.model = BHS_GIN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist)\n",
    "                self.target_model = BHS_GIN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist)\n",
    "            \n",
    "        elif (network == \"NN\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                edge_attr = self.env.edge_attr.to(self.device)\n",
    "                edge_attr = edge_attr.view(edge_attr.shape[0],1)\n",
    "                self.model = BHS_NN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_attr)\n",
    "                self.target_model = BHS_NN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_attr)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                edge_attr = torch.ones([edgelist.shape[1],1],dtype=torch.float).to(self.device)\n",
    "                self.model = BHS_NN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_attr)\n",
    "                self.target_model = BHS_NN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_attr)\n",
    "                \n",
    "        elif (network == \"CG\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                edge_attr = self.env.edge_attr.to(self.device)\n",
    "                edge_attr = edge_attr.view(edge_attr.shape[0],1)\n",
    "                self.model = BHS_CG([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_attr)\n",
    "                self.target_model = BHS_CG([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_attr)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                edge_attr = torch.ones([edgelist.shape[1],1],dtype=torch.float).to(self.device)\n",
    "                self.model = BHS_CG(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_attr)\n",
    "                self.target_model = BHS_CG(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_attr)\n",
    "                \n",
    "        elif (network == \"PNA\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                edge_attr = self.env.edge_attr.to(self.device)\n",
    "                edge_attr = edge_attr.view(edge_attr.shape[0],1)\n",
    "                self.model = BHS_PNA([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_attr)\n",
    "                self.target_model = BHS_PNA([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_attr)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                edge_attr = torch.ones([edgelist.shape[1],1],dtype=torch.float).to(self.device)\n",
    "                self.model = BHS_PNA(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_attr)\n",
    "                self.target_model = BHS_PNA(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_attr)\n",
    "            \n",
    "        elif (network == \"GCN_DQN\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                edge_weight = self.env.edge_attr.to(self.device)\n",
    "                self.model = BHS_GCN_DQN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                self.target_model = BHS_GCN_DQN([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_weight)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                edge_weight = torch.ones([edgelist.shape[1]],dtype=torch.float).to(self.device)\n",
    "                self.model = BHS_GCN_DQN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                self.target_model = BHS_GCN_DQN(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_weight)\n",
    "                \n",
    "        elif (network == \"TEST\"):\n",
    "            print(\"Model =\", network)\n",
    "            if (downsampled):\n",
    "                edgelist = self.env.edgelist_down.to(self.device)\n",
    "                edge_attr = self.env.edge_attr.to(self.device)\n",
    "                edge_attr = edge_attr.view(edge_attr.shape[0],1)\n",
    "                hidden = torch.zeros([1,len(self.env.nodes),128],dtype=torch.float).to(self.device)\n",
    "                self.model = BHS_TEST([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_attr, hidden)\n",
    "                self.target_model = BHS_TEST([len(self.env.nodes),self.env.observation_space.shape[1]], self.env.action_space.nvec, edgelist, edge_attr, hidden)\n",
    "            else: \n",
    "                edgelist = self.env.edgelist.to(self.device)\n",
    "                edge_attr = torch.ones([edgelist.shape[1],1],dtype=torch.float).to(self.device)\n",
    "                hidden = torch.zeros([5,self.env.observation_space.shape[0],128],dtype=torch.float).to(self.device)\n",
    "                self.model = BHS_TEST(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_attr, hidden)\n",
    "                self.target_model = BHS_TEST(self.env.observation_space.shape, self.env.action_space.nvec, edgelist, edge_attr, hidden)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Network not chosen - Choose DQN, GCN, GAT, SGN, GGNN, SAGE, GIN, NN, CG, PNA, GCN_DQN or TEST\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-27-17\n",
      "Number of elements in environment:  101\n",
      "Downsampled:  False\n",
      "Number of nodes: 101\n",
      "RL_DIVERTERS [2, 5, 13, 19, 26, 37, 92]\n",
      "Model = GAT\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-94754ae0e190>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[0mstart_update\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_observation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0mepisode_reward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mtime_update\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart_update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Github\\DeepRL-Tutorials\\agents\\DQN.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, s, a, r, s_, frame)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;31m# Optimize the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\BHS_Pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\BHS_Pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start=timer()\n",
    "\n",
    "if (get_ipython().__class__.__name__ == \"ZMQInteractiveShell\"):\n",
    "    network = \"GAT\"\n",
    "    downsampled = False\n",
    "elif (len(sys.argv) > 2):\n",
    "    network = sys.argv[1]\n",
    "    downsampled = sys.argv[2]\n",
    "    if (downsampled == \"True\"):\n",
    "        downsampled = True\n",
    "    elif (downsampled == \"False\"):\n",
    "        downsampled = False\n",
    "    else:\n",
    "        raise ValueError(\"Downsampling not chosen - Choose True or False\")\n",
    "else:\n",
    "    raise ValueError(\"Network or downsampling not chosen\")\n",
    "\n",
    "\n",
    "time = '{date:%Y-%m-%d-%H}'.format(date=datetime.datetime.now())\n",
    "print(time)\n",
    "\n",
    "log_dir = \"tmp/\" + network + \"/\"\n",
    "res_dir = \"Results/\" + network + \"/\"\n",
    "filename = res_dir + network + \"_\" + time\n",
    "try:\n",
    "    os.makedirs(res_dir, exist_ok = True)\n",
    "    os.makedirs(log_dir)\n",
    "except OSError:\n",
    "    files = glob.glob(os.path.join(log_dir, '*.monitor.csv')) \\\n",
    "        + glob.glob(os.path.join(log_dir, '*td.csv')) \\\n",
    "        + glob.glob(os.path.join(log_dir, '*sig_param_mag.csv')) \\\n",
    "        + glob.glob(os.path.join(log_dir, '*action_log.csv'))\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "\n",
    "class Arg_parser():\n",
    "    def __init__(self):\n",
    "        self.max_timesteps = 10000000\n",
    "        self.envtype = 'env_2_0'\n",
    "        self.tb_log_name = 'DQN'\n",
    "        self.steplimit = 200\n",
    "        self.log_interval = 1000\n",
    "        self.step_penalty = None\n",
    "        self.trasum_scale = None\n",
    "        self.destination_score = None\n",
    "        self.numtotes = 30\n",
    "        self.randomize_numtotes = False\n",
    "        self.RL_diverters = None\n",
    "        self.downsampled = downsampled\n",
    "    \n",
    "args = Arg_parser()\n",
    "\n",
    "env_id = args.envtype\n",
    "env    = Environment(args) #make_atari(env_id)\n",
    "env    = bench.Monitor(env, os.path.join(log_dir, env_id))\n",
    "# env    = wrap_deepmind(env, episode_life=True, clip_rewards=True, frame_stack=False, scale=True)\n",
    "# env    = ImageToPyTorch(env)\n",
    "model  = Model(env=env, config=config, log_dir=log_dir, network=network, downsampled=downsampled)\n",
    "\n",
    "episode_reward = 0\n",
    "time_get, time_step, time_update = 0,0,0\n",
    "observation = env.reset(total = True)\n",
    "\n",
    "for frame_idx in range(1, config.MAX_FRAMES + 1):\n",
    "    epsilon = config.epsilon_by_frame(frame_idx)\n",
    "\n",
    "    start_get=timer()\n",
    "    action = model.get_action(observation, epsilon)[0]\n",
    "    time_get += timer()-start_get\n",
    "    \n",
    "    start_step=timer()\n",
    "    prev_observation=observation\n",
    "    observation, reward, done, _, actual_action = env.step(action)\n",
    "    observation = None if env.deadlock else observation\n",
    "    time_step += timer()-start_step\n",
    "    \n",
    "    action = actual_action\n",
    "    model.save_action(action, frame_idx) #log action selection\n",
    "    \n",
    "    start_update=timer()\n",
    "    model.update(prev_observation, action, reward, observation, frame_idx)\n",
    "    episode_reward += reward\n",
    "    time_update += timer()-start_update\n",
    "    \n",
    "    if frame_idx % args.steplimit*10 == 0:\n",
    "        total_reset = True\n",
    "    else:\n",
    "        total_reset = env.deadlock\n",
    "    if done:\n",
    "        model.finish_nstep()\n",
    "        model.reset_hx()\n",
    "        \n",
    "        observation = env.reset(total=total_reset)\n",
    "        model.save_reward(episode_reward)\n",
    "        episode_reward = 0\n",
    "    \n",
    "    \n",
    "    if frame_idx % args.log_interval == 0:\n",
    "        torch.save(model.get_state_dict(), filename + \".pt\") #model.save_w()\n",
    "        try:\n",
    "            clear_output(True)\n",
    "            print(frame_idx)\n",
    "            print(time_get/args.log_interval, time_step/args.log_interval, time_update/args.log_interval)\n",
    "            time_get, time_step, time_update = 0,0,0\n",
    "            plot_all_data(log_dir, env_id, 'BHSDuelingDQN', config.MAX_FRAMES, bin_size=(10, 100, 100, 1), smooth=1, time=timedelta(seconds=int(timer()-start)), save_filename=filename+\".svg\", ipynb=False)\n",
    "        except IOError:\n",
    "            pass\n",
    "\n",
    "torch.save(model.get_state_dict(), filename + \".pt\") #model.save_w()\n",
    "env.close()\n",
    "plot_all_data(log_dir, env_id, 'BHSDuelingDQN', config.MAX_FRAMES, bin_size=(10, 100, 100, 1), smooth=1, time=timedelta(seconds=int(timer()-start)), save_filename=filename+\".svg\", ipynb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
